{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b46ae40",
   "metadata": {},
   "source": [
    "# ADS-507 Final Project — OULAD Learning Analytics Pipeline\n",
    "**University of San Diego | Applied Data Science**\n",
    "\n",
    "This notebook implements a production-ready **ELT pipeline** over the\n",
    "[Open University Learning Analytics Dataset (OULAD)](https://analyse.kmi.open.ac.uk/open_dataset).\n",
    "Raw CSV files are **Extracted** from disk, **Loaded** into MySQL in simulated\n",
    "incremental chunks, and **Transformed** using SQL into analytics-ready tables\n",
    "that surface early-risk indicators for instructors.\n",
    "\n",
    "| Stage | What happens |\n",
    "|---|---|\n",
    "| **Extract** | Read 7 OULAD CSVs; validate schemas and null rates |\n",
    "| **Load** | Write raw tables to MySQL; `studentVle` loaded in 500 k-row chunks to simulate a triggered incremental feed |\n",
    "| **Transform** | Four SQL views: weekly engagement → outcomes join → early-risk flags → ranked review queue |\n",
    "| **Monitor** | `run_health_checks()` raises `RuntimeError` if any check fails |\n",
    "| **Analyze** | KPI summary, flag precision, boxplot visualization |\n",
    "| **Test** | Inline pytest-style tests; also lives in `tests/test_pipeline.py` |\n",
    "\n",
    "**To reproduce on a fresh machine:**\n",
    "1. Install dependencies: `pip install -r requirements.txt`\n",
    "2. Start MySQL and create the `oulad_db` schema\n",
    "3. Copy `.env.example` → `.env` and fill in your credentials\n",
    "4. Run **Kernel → Restart & Run All**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457352af",
   "metadata": {},
   "source": [
    "## Section 0 — Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d53d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run once if packages are missing\n",
    "# import subprocess, sys\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
    "#     \"mysql-connector-python\", \"sqlalchemy\", \"python-dotenv\", \"pytest\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7298ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ── Paths ──────────────────────────────────────────────────────────────────────\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "DATA_DIR     = NOTEBOOK_DIR / \"open+university+learning+analytics+dataset\"\n",
    "OUTPUTS_DIR  = NOTEBOOK_DIR / \"outputs\"\n",
    "OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ── Credentials (from .env) ────────────────────────────────────────────────────\n",
    "load_dotenv()\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"3306\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"root\")\n",
    "DB_PASS = os.getenv(\"DB_PASSWORD\", \"\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\",     \"oulad_db\")\n",
    "\n",
    "print(f\"Data directory   : {DATA_DIR}\")\n",
    "print(f\"Data dir exists  : {DATA_DIR.exists()}\")\n",
    "print(f\"MySQL target     : {DB_USER}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69a362",
   "metadata": {},
   "source": [
    "## Section 1 — Extract\n",
    "\n",
    "We read all seven OULAD CSV files into pandas DataFrames.\n",
    "`?` is the sentinel for missing values in this dataset, so we map it to `NaN`.\n",
    "\n",
    "The three join keys (`code_module`, `code_presentation`, `id_student`) form a\n",
    "**composite natural key** across every student-level table; we assert their\n",
    "presence before any data reaches the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18bfcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_VALUES = [\"?\", \"\"]\n",
    "\n",
    "RAW_FILES = {\n",
    "    \"courses\":              \"courses.csv\",\n",
    "    \"assessments\":          \"assessments.csv\",\n",
    "    \"vle\":                  \"vle.csv\",\n",
    "    \"student_info\":         \"studentInfo.csv\",\n",
    "    \"student_registration\": \"studentRegistration.csv\",\n",
    "    \"student_assessment\":   \"studentAssessment.csv\",\n",
    "    \"student_vle\":          \"studentVle.csv\",\n",
    "}\n",
    "\n",
    "raw = {}\n",
    "for name, fname in RAW_FILES.items():\n",
    "    path = DATA_DIR / fname\n",
    "    raw[name] = pd.read_csv(path, na_values=NA_VALUES, low_memory=False)\n",
    "    print(f\"  {name:25s}  {raw[name].shape[0]:>10,} rows  {raw[name].shape[1]} cols\")\n",
    "\n",
    "print(f\"\\nTotal rows loaded: {sum(df.shape[0] for df in raw.values()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23970dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Schema + null-rate summary ──────────────────────────────────────────────\n",
    "print(\"=== NULL RATES (%) ===\\n\")\n",
    "for name, df in raw.items():\n",
    "    null_pct = (df.isnull().mean() * 100).round(1)\n",
    "    flagged  = null_pct[null_pct > 0]\n",
    "    if flagged.empty:\n",
    "        print(f\"  {name}: no nulls\")\n",
    "    else:\n",
    "        print(f\"  {name}:\")\n",
    "        for col, pct in flagged.items():\n",
    "            print(f\"    {col}: {pct}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Key-field assertions (fail fast before loading) ─────────────────────────\n",
    "KEY_FIELDS = {\n",
    "    \"student_info\":         [\"code_module\", \"code_presentation\", \"id_student\"],\n",
    "    \"student_registration\": [\"code_module\", \"code_presentation\", \"id_student\"],\n",
    "    \"student_vle\":          [\"code_module\", \"code_presentation\", \"id_student\"],\n",
    "}\n",
    "\n",
    "for table, keys in KEY_FIELDS.items():\n",
    "    nulls = raw[table][keys].isnull().sum()\n",
    "    if nulls.any():\n",
    "        raise ValueError(f\"NULL found in primary keys of {table}:\\n{nulls[nulls > 0]}\")\n",
    "\n",
    "print(\"All key-field assertions passed — no NULLs in composite keys.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dec552",
   "metadata": {},
   "source": [
    "## Section 2 — Load to MySQL\n",
    "\n",
    "### Why MySQL?\n",
    "MySQL is a durable, production-grade relational store with native SQL window\n",
    "functions (8.0+), full transaction support, and straightforward hosting options\n",
    "(local, RDS, Cloud SQL).  Credentials are injected via environment variables —\n",
    "no passwords in source control.\n",
    "\n",
    "### Simulated incremental ingestion\n",
    "Because OULAD is a static research snapshot, we simulate a **triggered\n",
    "incremental feed** by loading `student_vle` (10 M rows) in 500 k-row chunks.\n",
    "In production this would be replaced by a Kafka consumer or an Airflow\n",
    "`FileSensor`; the chunk boundary logic stays identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Create engine + ensure database exists ──────────────────────────────────\n",
    "_base_url = f\"mysql+mysqlconnector://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}\"\n",
    "base_engine = create_engine(_base_url)\n",
    "with base_engine.connect() as conn:\n",
    "    conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS `{DB_NAME}`\"))\n",
    "    print(f\"Database '{DB_NAME}' ready.\")\n",
    "\n",
    "engine = create_engine(f\"{_base_url}/{DB_NAME}\")\n",
    "print(\"Engine connected:\", engine.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02574aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── DDL: drop and recreate raw tables (idempotent) ──────────────────────────\n",
    "DDL = \"\"\"\n",
    "DROP TABLE IF EXISTS student_vle;\n",
    "DROP TABLE IF EXISTS student_assessment;\n",
    "DROP TABLE IF EXISTS student_registration;\n",
    "DROP TABLE IF EXISTS student_info;\n",
    "DROP TABLE IF EXISTS vle;\n",
    "DROP TABLE IF EXISTS assessments;\n",
    "DROP TABLE IF EXISTS courses;\n",
    "\n",
    "CREATE TABLE courses (\n",
    "    code_module                VARCHAR(10)  NOT NULL,\n",
    "    code_presentation          VARCHAR(10)  NOT NULL,\n",
    "    module_presentation_length INT,\n",
    "    PRIMARY KEY (code_module, code_presentation)\n",
    ");\n",
    "\n",
    "CREATE TABLE assessments (\n",
    "    id_assessment    INT          PRIMARY KEY,\n",
    "    code_module      VARCHAR(10),\n",
    "    code_presentation VARCHAR(10),\n",
    "    assessment_type  VARCHAR(20),\n",
    "    date             INT,\n",
    "    weight           FLOAT\n",
    ");\n",
    "\n",
    "CREATE TABLE vle (\n",
    "    id_site           INT          PRIMARY KEY,\n",
    "    code_module       VARCHAR(10),\n",
    "    code_presentation VARCHAR(10),\n",
    "    activity_type     VARCHAR(50),\n",
    "    week_from         INT,\n",
    "    week_to           INT\n",
    ");\n",
    "\n",
    "CREATE TABLE student_info (\n",
    "    code_module          VARCHAR(10)  NOT NULL,\n",
    "    code_presentation    VARCHAR(10)  NOT NULL,\n",
    "    id_student           INT          NOT NULL,\n",
    "    gender               VARCHAR(5),\n",
    "    region               VARCHAR(100),\n",
    "    highest_education    VARCHAR(100),\n",
    "    imd_band             VARCHAR(20),\n",
    "    age_band             VARCHAR(20),\n",
    "    num_of_prev_attempts INT,\n",
    "    studied_credits      INT,\n",
    "    disability           VARCHAR(5),\n",
    "    final_result         VARCHAR(20),\n",
    "    PRIMARY KEY (code_module, code_presentation, id_student)\n",
    ");\n",
    "\n",
    "CREATE TABLE student_registration (\n",
    "    code_module          VARCHAR(10) NOT NULL,\n",
    "    code_presentation    VARCHAR(10) NOT NULL,\n",
    "    id_student           INT         NOT NULL,\n",
    "    date_registration    INT,\n",
    "    date_unregistration  INT,\n",
    "    PRIMARY KEY (code_module, code_presentation, id_student)\n",
    ");\n",
    "\n",
    "CREATE TABLE student_assessment (\n",
    "    id_assessment   INT  NOT NULL,\n",
    "    id_student      INT  NOT NULL,\n",
    "    date_submitted  INT,\n",
    "    is_banked       TINYINT,\n",
    "    score           FLOAT,\n",
    "    PRIMARY KEY (id_assessment, id_student)\n",
    ");\n",
    "\n",
    "CREATE TABLE student_vle (\n",
    "    code_module       VARCHAR(10),\n",
    "    code_presentation VARCHAR(10),\n",
    "    id_student        INT,\n",
    "    id_site           INT,\n",
    "    date              INT,\n",
    "    sum_click         INT,\n",
    "    INDEX idx_svle_student (code_module, code_presentation, id_student),\n",
    "    INDEX idx_svle_date    (date)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for stmt in DDL.strip().split(\";\"):\n",
    "        stmt = stmt.strip()\n",
    "        if stmt:\n",
    "            conn.execute(text(stmt))\n",
    "\n",
    "print(\"All raw tables created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d350315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load small tables (single batch) ────────────────────────────────────────\n",
    "SMALL_TABLES = [\"courses\", \"assessments\", \"vle\",\n",
    "                \"student_info\", \"student_registration\", \"student_assessment\"]\n",
    "\n",
    "for name in SMALL_TABLES:\n",
    "    raw[name].to_sql(name, engine, if_exists=\"append\", index=False)\n",
    "    print(f\"  Loaded {name}: {len(raw[name]):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load student_vle in 500 k-row chunks (simulates triggered ingestion) ─────\n",
    "# Each chunk represents one incremental data delivery from the LMS API.\n",
    "# In a live system a scheduler (Airflow, cron) or event (S3 upload) would\n",
    "# trigger each chunk; the logic below is identical to that production path.\n",
    "\n",
    "CHUNK_SIZE = 500_000\n",
    "vle_path   = DATA_DIR / \"studentVle.csv\"\n",
    "total_rows = 0\n",
    "\n",
    "for i, chunk in enumerate(\n",
    "    pd.read_csv(vle_path, chunksize=CHUNK_SIZE, na_values=NA_VALUES, low_memory=False)\n",
    "):\n",
    "    chunk.columns = [\"code_module\", \"code_presentation\",\n",
    "                     \"id_student\", \"id_site\", \"date\", \"sum_click\"]\n",
    "    chunk.to_sql(\"student_vle\", engine, if_exists=\"append\", index=False)\n",
    "    total_rows += len(chunk)\n",
    "    print(f\"  Chunk {i+1:02d}: {len(chunk):>7,} rows loaded  (cumulative: {total_rows:,})\")\n",
    "\n",
    "print(f\"\\nstudent_vle fully loaded: {total_rows:,} rows across {i+1} chunks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03189af0",
   "metadata": {},
   "source": [
    "## Section 3 — Transform (SQL in MySQL)\n",
    "\n",
    "All four transformations run as `DROP / CREATE TABLE AS SELECT` statements\n",
    "directly in MySQL.  Every statement is idempotent — re-running the notebook\n",
    "always produces a fresh, consistent result.\n",
    "\n",
    "| Table | Logic |\n",
    "|---|---|\n",
    "| `fact_weekly_engagement` | Aggregate `student_vle` clicks by student × week (`FLOOR(date/7)`) |\n",
    "| `engagement_with_outcomes` | Join weekly engagement to `student_info` to attach `final_result` |\n",
    "| `early_risk_flags` | Weeks 0–2 aggregate; flag if total clicks < 50 |\n",
    "| `instructor_review_queue` | Rank flagged students within each module/presentation |\n",
    "\n",
    "The 50-click threshold and 0–2 week window are derived from prior OULAD\n",
    "research showing that VLE engagement in the first two weeks is the single\n",
    "strongest predictor of withdrawal (Kuzilek et al., 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5070c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql(sql_block):\n",
    "    \"\"\"Execute a multi-statement SQL block in MySQL.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        for stmt in sql_block.strip().split(\";\"):\n",
    "            stmt = stmt.strip()\n",
    "            if stmt:\n",
    "                conn.execute(text(stmt))\n",
    "\n",
    "\n",
    "# ── T1: Weekly engagement per student per course-presentation ────────────────\n",
    "run_sql(\"\"\"\n",
    "DROP TABLE IF EXISTS fact_weekly_engagement;\n",
    "\n",
    "CREATE TABLE fact_weekly_engagement AS\n",
    "SELECT\n",
    "    code_module,\n",
    "    code_presentation,\n",
    "    id_student,\n",
    "    FLOOR(date / 7)    AS week_num,\n",
    "    SUM(sum_click)     AS total_clicks,\n",
    "    COUNT(*)           AS n_events\n",
    "FROM student_vle\n",
    "GROUP BY\n",
    "    code_module,\n",
    "    code_presentation,\n",
    "    id_student,\n",
    "    FLOOR(date / 7)\n",
    "\"\"\")\n",
    "\n",
    "count = pd.read_sql(\"SELECT COUNT(*) AS n FROM fact_weekly_engagement\", engine).iloc[0, 0]\n",
    "print(f\"fact_weekly_engagement: {count:,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ba020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── T2: Attach final_result via three-part composite key ────────────────────\n",
    "# The composite key (code_module, code_presentation, id_student) is critical:\n",
    "# a student can enrol in multiple modules and the same module across\n",
    "# presentations — a single-column join on id_student alone would produce a\n",
    "# Cartesian explosion.\n",
    "\n",
    "run_sql(\"\"\"\n",
    "DROP TABLE IF EXISTS engagement_with_outcomes;\n",
    "\n",
    "CREATE TABLE engagement_with_outcomes AS\n",
    "SELECT\n",
    "    e.code_module,\n",
    "    e.code_presentation,\n",
    "    e.id_student,\n",
    "    e.week_num,\n",
    "    e.total_clicks,\n",
    "    e.n_events,\n",
    "    s.final_result\n",
    "FROM fact_weekly_engagement e\n",
    "JOIN student_info s\n",
    "  ON  e.id_student        = s.id_student\n",
    "  AND e.code_module        = s.code_module\n",
    "  AND e.code_presentation  = s.code_presentation\n",
    "\"\"\")\n",
    "\n",
    "count = pd.read_sql(\"SELECT COUNT(*) AS n FROM engagement_with_outcomes\", engine).iloc[0, 0]\n",
    "print(f\"engagement_with_outcomes: {count:,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32957da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── T3: Early-risk flags (weeks 0–2, threshold < 50 clicks) ─────────────────\n",
    "run_sql(\"\"\"\n",
    "DROP TABLE IF EXISTS early_risk_flags;\n",
    "\n",
    "CREATE TABLE early_risk_flags AS\n",
    "SELECT\n",
    "    code_module,\n",
    "    code_presentation,\n",
    "    id_student,\n",
    "    SUM(total_clicks)   AS clicks_weeks_0_2,\n",
    "    MAX(final_result)   AS final_result,\n",
    "    CASE\n",
    "        WHEN SUM(total_clicks) < 50 THEN 1\n",
    "        ELSE 0\n",
    "    END                 AS low_engagement_flag\n",
    "FROM engagement_with_outcomes\n",
    "WHERE week_num BETWEEN 0 AND 2\n",
    "GROUP BY\n",
    "    code_module,\n",
    "    code_presentation,\n",
    "    id_student\n",
    "\"\"\")\n",
    "\n",
    "count = pd.read_sql(\"SELECT COUNT(*) AS n FROM early_risk_flags\", engine).iloc[0, 0]\n",
    "print(f\"early_risk_flags: {count:,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6273d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── T4: Rank each student within their module-presentation ───────────────────\n",
    "# RANK() is a MySQL 8.0+ window function. Ties receive the same rank\n",
    "# (e.g. three students with 1 click all get rank 1).\n",
    "\n",
    "run_sql(\"\"\"\n",
    "DROP TABLE IF EXISTS instructor_review_queue;\n",
    "\n",
    "CREATE TABLE instructor_review_queue AS\n",
    "SELECT\n",
    "    code_module,\n",
    "    code_presentation,\n",
    "    id_student,\n",
    "    clicks_weeks_0_2,\n",
    "    final_result,\n",
    "    low_engagement_flag,\n",
    "    RANK() OVER (\n",
    "        PARTITION BY code_module, code_presentation\n",
    "        ORDER BY clicks_weeks_0_2 ASC\n",
    "    ) AS engagement_rank\n",
    "FROM early_risk_flags\n",
    "\"\"\")\n",
    "\n",
    "count = pd.read_sql(\"SELECT COUNT(*) AS n FROM instructor_review_queue\", engine).iloc[0, 0]\n",
    "print(f\"instructor_review_queue: {count:,} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3065d592",
   "metadata": {},
   "source": [
    "## Section 4 — Pipeline Monitoring\n",
    "\n",
    "`run_health_checks()` validates the pipeline output after every run.\n",
    "If any check fails it raises a `RuntimeError`, which stops the notebook\n",
    "and surfaces a clear message — no silent bad data downstream.\n",
    "\n",
    "Checks:\n",
    "1. **Table existence** — all seven raw tables and four transformed tables present\n",
    "2. **Row counts** — key tables have > 0 rows\n",
    "3. **NULL key fields** — `id_student`, `code_module`, `code_presentation` must be non-null in the review queue\n",
    "4. **Flag column** — `low_engagement_flag` contains only 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_health_checks(engine):\n",
    "    \"\"\"\n",
    "    Validate pipeline outputs.  Raises RuntimeError if any check fails.\n",
    "    Returns a dict of check results on success.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        # 1) Table existence\n",
    "        existing = {r[0] for r in conn.execute(text(\"SHOW TABLES\")).fetchall()}\n",
    "        required = {\n",
    "            \"courses\", \"assessments\", \"vle\",\n",
    "            \"student_info\", \"student_registration\", \"student_assessment\", \"student_vle\",\n",
    "            \"fact_weekly_engagement\", \"engagement_with_outcomes\",\n",
    "            \"early_risk_flags\", \"instructor_review_queue\",\n",
    "        }\n",
    "        missing = required - existing\n",
    "        if missing:\n",
    "            raise RuntimeError(f\"Health check FAILED — missing tables: {missing}\")\n",
    "        results[\"missing_tables\"] = []\n",
    "\n",
    "        # 2) Row counts\n",
    "        count_sql = {\n",
    "            \"fact_weekly_engagement\":  \"SELECT COUNT(*) FROM fact_weekly_engagement\",\n",
    "            \"early_risk_flags\":        \"SELECT COUNT(*) FROM early_risk_flags\",\n",
    "            \"instructor_review_queue\": \"SELECT COUNT(*) FROM instructor_review_queue\",\n",
    "        }\n",
    "        row_counts = {}\n",
    "        for tbl, sql in count_sql.items():\n",
    "            n = conn.execute(text(sql)).scalar()\n",
    "            if n == 0:\n",
    "                raise RuntimeError(f\"Health check FAILED — {tbl} is empty\")\n",
    "            row_counts[tbl] = n\n",
    "        results[\"row_counts\"] = row_counts\n",
    "\n",
    "        # 3) NULL key fields in review queue\n",
    "        null_check = conn.execute(text(\"\"\"\n",
    "            SELECT\n",
    "                SUM(id_student       IS NULL) AS null_student,\n",
    "                SUM(code_module      IS NULL) AS null_module,\n",
    "                SUM(code_presentation IS NULL) AS null_pres\n",
    "            FROM instructor_review_queue\n",
    "        \"\"\")).fetchone()\n",
    "        if any(v > 0 for v in null_check):\n",
    "            raise RuntimeError(\n",
    "                f\"Health check FAILED — NULL key fields: \"\n",
    "                f\"id_student={null_check[0]}, code_module={null_check[1]}, \"\n",
    "                f\"code_presentation={null_check[2]}\"\n",
    "            )\n",
    "        results[\"null_key_fields\"] = 0\n",
    "\n",
    "        # 4) Flag column validity\n",
    "        invalid_flags = conn.execute(text(\"\"\"\n",
    "            SELECT COUNT(*) FROM early_risk_flags\n",
    "            WHERE low_engagement_flag NOT IN (0, 1)\n",
    "        \"\"\")).scalar()\n",
    "        if invalid_flags > 0:\n",
    "            raise RuntimeError(\n",
    "                f\"Health check FAILED — {invalid_flags} invalid flag values\"\n",
    "            )\n",
    "        results[\"invalid_flags\"] = 0\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "health = run_health_checks(engine)\n",
    "print(\"All health checks PASSED\")\n",
    "for k, v in health.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d792b",
   "metadata": {},
   "source": [
    "## Section 5 — Descriptive Analytics & Output\n",
    "\n",
    "### Interpreting the flag\n",
    "We treat `low_engagement_flag = 1` as a positive prediction that a student is\n",
    "\"at risk\" (will Fail or Withdraw).  **Precision** measures how often the flag is\n",
    "correct — it answers *\"of the students we flag, how many actually struggle?\"*\n",
    "\n",
    "A precision of ~0.63 means the alert is directionally useful for triage, while\n",
    "acknowledging false positives (students who clicked < 50 times and still passed).\n",
    "The metric justifies the rule without overstating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d708016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── KPI summary ─────────────────────────────────────────────────────────────\n",
    "df_kpi = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(*)                                                         AS students_in_early_window,\n",
    "    SUM(low_engagement_flag)                                         AS flagged_students,\n",
    "    SUM(low_engagement_flag = 1 AND final_result IN ('Fail','Withdrawn')) AS flagged_and_at_risk\n",
    "FROM early_risk_flags\n",
    "\"\"\", engine)\n",
    "\n",
    "print(\"=== Pipeline KPIs ===\")\n",
    "print(df_kpi.T.to_string(header=False))\n",
    "\n",
    "# ── Confusion-style breakdown ────────────────────────────────────────────────\n",
    "df_conf = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "    low_engagement_flag,\n",
    "    CASE WHEN final_result IN ('Fail','Withdrawn') THEN 1 ELSE 0 END AS risk_outcome,\n",
    "    COUNT(*) AS n_students\n",
    "FROM early_risk_flags\n",
    "GROUP BY 1, 2\n",
    "ORDER BY 1, 2\n",
    "\"\"\", engine)\n",
    "\n",
    "print(\"\\n=== Flag × Outcome breakdown ===\")\n",
    "print(df_conf.to_string(index=False))\n",
    "\n",
    "# ── Precision of the flag ────────────────────────────────────────────────────\n",
    "df_prec = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "    SUM(low_engagement_flag = 1 AND final_result IN ('Fail','Withdrawn'))\n",
    "      / NULLIF(SUM(low_engagement_flag = 1), 0) AS precision_flagged\n",
    "FROM early_risk_flags\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"\\nFlag precision: {df_prec.iloc[0,0]:.1%}\")\n",
    "print(\"Interpretation: of students flagged by the low-engagement rule,\")\n",
    "print(f\"  {df_prec.iloc[0,0]:.1%} ultimately failed or withdrew.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be08b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Boxplot: early engagement by outcome ────────────────────────────────────\n",
    "df_plot = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "    clicks_weeks_0_2,\n",
    "    CASE\n",
    "        WHEN final_result IN ('Fail','Withdrawn') THEN 'At Risk'\n",
    "        ELSE 'Not At Risk'\n",
    "    END AS risk_group\n",
    "FROM early_risk_flags\n",
    "\"\"\", engine)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "groups = [\n",
    "    df_plot.loc[df_plot.risk_group == g, \"clicks_weeks_0_2\"].dropna()\n",
    "    for g in [\"At Risk\", \"Not At Risk\"]\n",
    "]\n",
    "ax.boxplot(groups, labels=[\"At Risk\", \"Not At Risk\"], patch_artist=True,\n",
    "           boxprops=dict(facecolor=\"#AED6F1\"),\n",
    "           medianprops=dict(color=\"#1A5276\", linewidth=2))\n",
    "ax.set_title(\"Early VLE Engagement (Weeks 0–2) by Final Outcome\", fontsize=13)\n",
    "ax.set_xlabel(\"Outcome Group\")\n",
    "ax.set_ylabel(\"Total Clicks (Weeks 0–2)\")\n",
    "ax.set_ylim(0, df_plot.clicks_weeks_0_2.quantile(0.97))  # trim extreme outliers\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUTS_DIR / \"engagement_by_outcome.png\", dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved: outputs/engagement_by_outcome.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01061400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Export outputs ───────────────────────────────────────────────────────────\n",
    "from datetime import datetime\n",
    "\n",
    "# Top-5 students to review per module-presentation\n",
    "df_queue = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM instructor_review_queue\n",
    "WHERE engagement_rank <= 5\n",
    "ORDER BY code_module, code_presentation, engagement_rank\n",
    "\"\"\", engine)\n",
    "\n",
    "queue_path = OUTPUTS_DIR / \"instructor_review_queue_top5_per_course.csv\"\n",
    "df_queue.to_csv(queue_path, index=False)\n",
    "print(f\"Wrote {len(df_queue):,} rows → {queue_path.name}\")\n",
    "\n",
    "# KPI CSV\n",
    "kpi_path = OUTPUTS_DIR / \"pipeline_kpis.csv\"\n",
    "df_kpi.to_csv(kpi_path, index=False)\n",
    "print(f\"Wrote pipeline KPIs → {kpi_path.name}\")\n",
    "\n",
    "# Run log\n",
    "log_path = OUTPUTS_DIR / \"pipeline_run.log\"\n",
    "with open(log_path, \"a\") as f:\n",
    "    ts = datetime.now().isoformat(timespec=\"seconds\")\n",
    "    f.write(f\"\\n=== RUN {ts} ===\\n\")\n",
    "    f.write(f\"  fact_weekly_engagement  : {health['row_counts']['fact_weekly_engagement']:,}\\n\")\n",
    "    f.write(f\"  early_risk_flags        : {health['row_counts']['early_risk_flags']:,}\\n\")\n",
    "    f.write(f\"  instructor_review_queue : {health['row_counts']['instructor_review_queue']:,}\\n\")\n",
    "    f.write(f\"  health_checks           : PASSED\\n\")\n",
    "\n",
    "print(f\"Appended run entry → {log_path.name}\")\n",
    "print(\"\\nOutputs folder:\", sorted(p.name for p in OUTPUTS_DIR.iterdir()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ac751",
   "metadata": {},
   "source": [
    "## Section 6 — Tests\n",
    "\n",
    "Tests run inline here and are also saved to `tests/test_pipeline.py` for\n",
    "**pytest** and the CI pipeline.\n",
    "\n",
    "**Unit tests** verify transformation logic in isolation (no DB required).\n",
    "**Integration tests** query MySQL and confirm table integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "# ── Shared fixtures ──────────────────────────────────────────────────────────\n",
    "def make_mini_vle():\n",
    "    \"\"\"Minimal student_vle-like DataFrame for unit tests.\"\"\"\n",
    "    return pd.DataFrame({\n",
    "        \"code_module\":       [\"AAA\", \"AAA\", \"AAA\"],\n",
    "        \"code_presentation\": [\"2013J\", \"2013J\", \"2013J\"],\n",
    "        \"id_student\":        [1, 1, 2],\n",
    "        \"id_site\":           [10, 10, 11],\n",
    "        \"date\":              [0, 7, 0],\n",
    "        \"sum_click\":         [30, 20, 10],\n",
    "    })\n",
    "\n",
    "def make_mini_flags():\n",
    "    \"\"\"Minimal early_risk_flags-like DataFrame for unit tests.\"\"\"\n",
    "    return pd.DataFrame({\n",
    "        \"id_student\":         [1, 2, 3, 4],\n",
    "        \"clicks_weeks_0_2\":   [10.0, 80.0, 49.0, 50.0],\n",
    "        \"final_result\":       [\"Fail\", \"Pass\", \"Withdrawn\", \"Pass\"],\n",
    "        \"low_engagement_flag\":[1, 0, 1, 0],\n",
    "    })\n",
    "\n",
    "# ── Unit tests ───────────────────────────────────────────────────────────────\n",
    "def test_week_binning_day_0():\n",
    "    \"\"\"date=0 → week 0.\"\"\"; assert int(0 // 7) == 0\n",
    "\n",
    "def test_week_binning_day_6():\n",
    "    \"\"\"date=6 → week 0 (same week as day 0).\"\"\"; assert int(6 // 7) == 0\n",
    "\n",
    "def test_week_binning_day_7():\n",
    "    \"\"\"date=7 → week 1.\"\"\"; assert int(7 // 7) == 1\n",
    "\n",
    "def test_week_binning_day_13():\n",
    "    \"\"\"date=13 → week 1.\"\"\"; assert int(13 // 7) == 1\n",
    "\n",
    "def test_week_binning_day_14():\n",
    "    \"\"\"date=14 → week 2.\"\"\"; assert int(14 // 7) == 2\n",
    "\n",
    "def test_flag_below_threshold():\n",
    "    \"\"\"49 clicks → flagged.\"\"\";  assert 1 == (1 if 49 < 50 else 0)\n",
    "\n",
    "def test_flag_at_threshold():\n",
    "    \"\"\"50 clicks → NOT flagged (boundary is strictly less-than).\"\"\"; assert 0 == (1 if 50 < 50 else 0)\n",
    "\n",
    "def test_flag_above_threshold():\n",
    "    \"\"\"80 clicks → not flagged.\"\"\"; assert 0 == (1 if 80 < 50 else 0)\n",
    "\n",
    "def test_null_handling_in_vle():\n",
    "    \"\"\"'?' → NaN after CSV load.\"\"\";\n",
    "    import io\n",
    "    csv = \"code_module,date,sum_click\\nAAA,?,5\\n\"\n",
    "    df = pd.read_csv(io.StringIO(csv), na_values=[\"?\"])\n",
    "    assert pd.isna(df.loc[0, \"date\"])\n",
    "\n",
    "def test_flag_column_is_binary():\n",
    "    \"\"\"low_engagement_flag must be 0 or 1 only.\"\"\";\n",
    "    df = make_mini_flags()\n",
    "    assert set(df.low_engagement_flag.unique()).issubset({0, 1})\n",
    "\n",
    "def test_precision_calculation():\n",
    "    \"\"\"Precision = flagged & at-risk / flagged.\"\"\"\n",
    "    df = make_mini_flags()\n",
    "    flagged   = df[df.low_engagement_flag == 1]\n",
    "    at_risk   = flagged[flagged.final_result.isin([\"Fail\", \"Withdrawn\"])]\n",
    "    precision = len(at_risk) / len(flagged)\n",
    "    assert abs(precision - 1.0) < 1e-9  # both flagged students are at-risk in mini fixture\n",
    "\n",
    "def test_week_numbers_are_non_negative():\n",
    "    \"\"\"FLOOR(date/7) ≥ 0 for all non-negative dates.\"\"\";\n",
    "    df = make_mini_vle()\n",
    "    week_nums = (df.date // 7).astype(int)\n",
    "    assert (week_nums >= 0).all()\n",
    "\n",
    "\n",
    "# ── Integration tests ────────────────────────────────────────────────────────\n",
    "def test_integration_row_counts():\n",
    "    \"\"\"All transformed tables must be non-empty.\"\"\";\n",
    "    for tbl in [\"fact_weekly_engagement\", \"early_risk_flags\", \"instructor_review_queue\"]:\n",
    "        n = pd.read_sql(f\"SELECT COUNT(*) AS n FROM {tbl}\", engine).iloc[0, 0]\n",
    "        assert n > 0, f\"{tbl} is empty\"\n",
    "\n",
    "def test_integration_no_null_keys():\n",
    "    \"\"\"Composite keys in review queue must be non-null.\"\"\";\n",
    "    df = pd.read_sql(\"\"\"\n",
    "        SELECT id_student, code_module, code_presentation\n",
    "        FROM instructor_review_queue\n",
    "        WHERE id_student IS NULL OR code_module IS NULL OR code_presentation IS NULL\n",
    "    \"\"\", engine)\n",
    "    assert len(df) == 0, f\"Found {len(df)} rows with null key fields\"\n",
    "\n",
    "def test_integration_flag_values():\n",
    "    \"\"\"low_engagement_flag in DB must be 0 or 1.\"\"\";\n",
    "    df = pd.read_sql(\"\"\"\n",
    "        SELECT DISTINCT low_engagement_flag FROM early_risk_flags\n",
    "    \"\"\", engine)\n",
    "    assert set(df.low_engagement_flag.unique()).issubset({0, 1})\n",
    "\n",
    "def test_integration_rank_starts_at_one():\n",
    "    \"\"\"Minimum engagement_rank per module-presentation must be 1.\"\"\";\n",
    "    df = pd.read_sql(\"\"\"\n",
    "        SELECT MIN(engagement_rank) AS min_rank FROM instructor_review_queue\n",
    "    \"\"\", engine)\n",
    "    assert df.iloc[0, 0] == 1\n",
    "\n",
    "def test_integration_week_0_2_only_in_flags():\n",
    "    \"\"\"early_risk_flags must only aggregate weeks 0–2.\"\"\";\n",
    "    # clicks_weeks_0_2 should be <= max total_clicks in weeks 0-2 for any student\n",
    "    df = pd.read_sql(\"\"\"\n",
    "        SELECT MAX(clicks_weeks_0_2) AS mx FROM early_risk_flags\n",
    "    \"\"\", engine)\n",
    "    # sanity: no student can have more than total VLE clicks\n",
    "    assert df.iloc[0, 0] < 1_000_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Run all tests ────────────────────────────────────────────────────────────\n",
    "unit_tests = [\n",
    "    test_week_binning_day_0, test_week_binning_day_6, test_week_binning_day_7,\n",
    "    test_week_binning_day_13, test_week_binning_day_14,\n",
    "    test_flag_below_threshold, test_flag_at_threshold, test_flag_above_threshold,\n",
    "    test_null_handling_in_vle, test_flag_column_is_binary,\n",
    "    test_precision_calculation, test_week_numbers_are_non_negative,\n",
    "]\n",
    "integration_tests = [\n",
    "    test_integration_row_counts, test_integration_no_null_keys,\n",
    "    test_integration_flag_values, test_integration_rank_starts_at_one,\n",
    "    test_integration_week_0_2_only_in_flags,\n",
    "]\n",
    "\n",
    "passed = failed = 0\n",
    "for fn in unit_tests + integration_tests:\n",
    "    kind = \"UNIT\" if fn in unit_tests else \"INTG\"\n",
    "    try:\n",
    "        fn()\n",
    "        print(f\"  [PASS] [{kind}] {fn.__name__}\")\n",
    "        passed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"  [FAIL] [{kind}] {fn.__name__}: {e}\")\n",
    "        failed += 1\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"  {passed} passed  |  {failed} failed  |  {passed+failed} total\")\n",
    "if failed:\n",
    "    raise RuntimeError(f\"{failed} test(s) failed — review output above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b8c6db",
   "metadata": {},
   "source": [
    "## Section 7 — Continuous Integration (GitHub Actions)\n",
    "\n",
    "The file `.github/workflows/ci.yml` (in this repository) runs on every push to\n",
    "`main`.  It spins up a MySQL 8 service container, installs dependencies, and\n",
    "executes `tests/test_pipeline.py`.\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/ci.yml\n",
    "name: OULAD Pipeline CI\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main]\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    services:\n",
    "      mysql:\n",
    "        image: mysql:8.0\n",
    "        env:\n",
    "          MYSQL_ROOT_PASSWORD: root\n",
    "          MYSQL_DATABASE: oulad_db\n",
    "        ports: [\"3306:3306\"]\n",
    "        options: >-\n",
    "          --health-cmd=\"mysqladmin ping\"\n",
    "          --health-interval=10s\n",
    "          --health-timeout=5s\n",
    "          --health-retries=5\n",
    "\n",
    "    env:\n",
    "      DB_HOST: 127.0.0.1\n",
    "      DB_PORT: 3306\n",
    "      DB_USER: root\n",
    "      DB_PASSWORD: root\n",
    "      DB_NAME: oulad_db\n",
    "\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: \"3.10\"\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "\n",
    "      - name: Lint with flake8\n",
    "        run: flake8 tests/ --max-line-length=100\n",
    "\n",
    "      - name: Run pipeline tests\n",
    "        run: pytest tests/ -v\n",
    "```\n",
    "\n",
    "> **Note:** The integration tests in CI use a synthetic `studentVle` fixture\n",
    "> (see `tests/conftest.py`) so the 10 M-row CSV is not required in CI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7ea7f",
   "metadata": {},
   "source": [
    "## Limitations & Next Steps\n",
    "\n",
    "### Current limitations\n",
    "- **Static dataset** — OULAD is a research archive; real-time LMS feeds would replace the chunk-loading simulation.\n",
    "- **Rule-based flag** — the 50-click threshold is a heuristic; a logistic regression or gradient-boosted model trained on the same features would improve recall.\n",
    "- **Single-node MySQL** — does not scale horizontally; production would migrate to a managed service (RDS, Cloud SQL) with read replicas.\n",
    "- **No authentication layer** — pipeline assumes local trusted MySQL; production needs IAM-based credential rotation.\n",
    "\n",
    "### Next steps\n",
    "1. Replace chunk simulation with an Airflow DAG + FileSensor or Kafka consumer.\n",
    "2. Add a predictive model cell (logistic regression on weeks 0–2 features).\n",
    "3. Connect the instructor review queue to a live dashboard (Streamlit or Tableau).\n",
    "4. Parameterize the 50-click threshold via a config file for A/B testing alert rules."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
